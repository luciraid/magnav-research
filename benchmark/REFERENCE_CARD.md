# ðŸ“Œ REFERENCE CARD

## One-Liner Commands

```bash
# Run tests (no data needed, ~5 seconds)
julia run_tests.jl

# Run main benchmark (auto-downloads data)
julia bench_tl_compare.jl

# Run all experiments
julia bench_tl_compare.jl && julia bench_multi_segment.jl && julia bench_sensitivity.jl

# Verify data access
julia verify_artifact_system.jl
```

## Where is my data?

```bash
~/.julia/artifacts/<hash>/sgl_2020_train/Flt1006_train.h5
```

**Don't worry about it â€” Julia manages it automatically!**

## Documentation Map

| I want to... | Read this |
|---|---|
| Get started in 30 seconds | [QUICK_START.md](QUICK_START.md) |
| Understand artifact system | [ARTIFACT_INTEGRATION.md](ARTIFACT_INTEGRATION.md) |
| Full setup guide | [SETUP_SUMMARY.md](SETUP_SUMMARY.md) |
| See what changed | This file (INTEGRATION_COMPLETE.md) |
| Learn the math | [custom_tl.jl](custom_tl.jl) |
| Understand benchmarks | [README.md](README.md) |

## Environment Variables (Optional)

```bash
# Custom output directory
RESULTS_DIR=/tmp/results julia bench_tl_compare.jl

# Add notes to results
RUN_NOTES="my test run" julia bench_tl_compare.jl

# Both together
RESULTS_DIR=/tmp/results RUN_NOTES="test" julia bench_tl_compare.jl
```

## Installed Test Status

```
âœ“ Julia 1.10.0
âœ“ MagNav installed
âœ“ DataFrames installed
âœ“ StatsBase installed
âœ“ All dependencies ready
âœ“ Tests: 10/10 passing
âœ“ Artifact system: Working
âœ“ Flight data: All 6 available
```

## If You Need Help

1. **Quick overview:** `cat QUICK_START.md`
2. **Something broken:** `julia verify_artifact_system.jl`
3. **Want to understand:** `cat ARTIFACT_INTEGRATION.md`
4. **Full details:** `cat SETUP_SUMMARY.md`

## Timeline

| When | Action | Result |
|------|--------|--------|
| Now | `julia run_tests.jl` | âœ“ Tests pass |
| Next | `julia bench_tl_compare.jl` | âœ“ Benchmark runs |
| Minutes | Check results | âœ“ Plots generated |
| Later | Modify code | âœ“ Re-run benchmarks |

## Key Files in Project

```
Core Algorithms
â”œâ”€â”€ custom_tl.jl ..................... 9-term TL model
â”œâ”€â”€ ekf_wrapper.jl ................... EKF navigation filter
â””â”€â”€ nav_metrics.jl ................... Error computations

Utilities
â”œâ”€â”€ data_loader.jl ................... Load HDF5 â†’ data structures
â”œâ”€â”€ segment_utils.jl ................. Flight segment handling
â”œâ”€â”€ experiment_config.jl ............. Configuration management
â””â”€â”€ tl_injection.jl .................. Inject compensation

Visualization
â””â”€â”€ bench_plots.jl ................... Generate figures

Benchmarks (RUN THESE)
â”œâ”€â”€ bench_tl_compare.jl .............. Main benchmark
â”œâ”€â”€ bench_multi_segment.jl ........... Multi-segment validation
â”œâ”€â”€ bench_sensitivity.jl ............. Parameter sweep
â”œâ”€â”€ run_tests.jl ..................... Unit tests
â””â”€â”€ verify_artifact_system.jl ........ Data verification

Documentation
â”œâ”€â”€ QUICK_START.md ................... Start here
â”œâ”€â”€ ARTIFACT_INTEGRATION.md .......... Data management details
â”œâ”€â”€ SETUP_SUMMARY.md ................. Full setup reference
â”œâ”€â”€ INTEGRATION_COMPLETE.md .......... This summary
â””â”€â”€ README.md ........................ Original framework docs
```

## Results Directory Structure

After running `julia bench_tl_compare.jl`:

```
results/
â””â”€â”€ run_20260217_150623/
    â”œâ”€â”€ config.txt
    â”œâ”€â”€ figures/
    â”‚   â”œâ”€â”€ trajectory_comparison.png
    â”‚   â”œâ”€â”€ heading_correlation.png
    â”‚   â””â”€â”€ ...
    â””â”€â”€ tables/
        â”œâ”€â”€ metrics_summary.csv
        â””â”€â”€ ...
```

## Quick Debugging

```bash
# Check if Julia works
julia --version

# Check if MagNav works
julia -e "using MagNav; println(\"OK\")"

# Check if artifacts work
julia verify_artifact_system.jl

# Check if tests pass
julia run_tests.jl

# Check current directory
pwd

# Check disk space
du -sh ~/.julia/artifacts
```

## Pro Tips

1. **First time running?** â†’ Expect ~1 min for data download
2. **Subsequent runs?** â†’ Much faster (cached data)
3. **Different flight?** â†’ Edit the H5_PATH line in benchmark script
4. **Parallel processing?** â†’ Use `julia -p auto bench_*.jl`
5. **Working directory?** â†’ Should be the magnav-benchmark folder

## What Happens When You Run `julia bench_tl_compare.jl`

```
1. Script loads â†’ checks dependencies
2. Calls sgl_2020_train() â†’ downloads artifact (if needed)
3. Opens Flt1006_train.h5 â†’ loads flight data
4. Splits data â†’ calibration + evaluation segments
5. Fits custom TL â†’ optimizes 9 coefficients
6. Compensates magnetic data â†’ applies correction
7. Runs EKF â†’ navigation simulation
8. Computes metrics â†’ RMS, DRMS, etc.
9. Saves results â†’ plots + CSV files
10. Done! â†’ Results in results/run_<timestamp>/
```

## FAQ

**Q: Why does it take time on first run?**  
A: Downloading and caching the 600MB+ artifact directory.

**Q: Can I use my own data?**  
A: Yes, modify the `load_benchmark_data()` function in data_loader.jl.

**Q: How do I use different flights?**  
A: Change `H5_PATH = joinpath(H5_DIR, "Flt1003_train.h5")` in benchmark script.

**Q: Is data stored in my repo?**  
A: No! It's in ~/.julia/artifacts/. Your repo stays clean.

**Q: What if artifact system fails?**  
A: Run `julia verify_artifact_system.jl` to diagnose.

---

**Status:** âœ“ Ready to Go  
**Last Check:** Tests passing (10/10)  
**Next Step:** `julia bench_tl_compare.jl`
